\section{Conclusion}
\label{sec:conclusion}

We present \toolname, a data-driven program repair approach for providing
type-error feedback. \toolname uses a dataset of ill-typed
programs and their fixed versions to learn a representative set of fix
templates, which we then use in a multi-class classification setting
to predict accurate fix templates for new ill-typed programs. These templates
guide the synthesis of program repairs.

On a corpus of 4,500 ill-typed \ocaml programs drawn from two instances of an
introductory programming course, we found that our machine learning models make
accurate fix template predictions 69\% of the time when considering the top
three templates and surpass 80\% when we consider the top six. We then showed
that using the predicted templates, we can synthesize repairs for over 70\% of
the test set in under 20 sec, compared to a 58\% repair rate of a \naive
implementation that doesn't use fix templates.

Finally, we conducted a user study with 29 participants which showed
that \toolname's repairs are of much better
quality than those from the state-of-the-art tool \seminal ($p=0.024$).
This improvement
shown by our data-driven method is especially significant because \seminal
incorporates expert-guided heuristics for improving the quality of error
messages by biasing its reports towards simpler and more useful ones. Thus, our
results demonstrate the unreasonable effectiveness of data for generating better
error messages.
