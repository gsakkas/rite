\section{Conclusion}
\label{sec:conclusion}

We presented \toolname, a data-driven program repair approach for providing
type-error feedback. \toolname utilizes a training dataset of pairs of ill-typed
programs and their fixed versions to learn a representative set of fix
templates, which we can then use in a multi-class classification problem setting
to predict accurate fix patterns for new ill-typed programs. These fix patterns
finally guiding the synthesis of program repairs.

On a corpus of 4,500 ill-typed \ocaml programs drawn from two instances of an
introductory programming course, we found that our machine learning models make
accurate fix template predictions 69\% of the time when considering the top
three templates and surpass 80\% when we consider the top six. We then showed
that using the predicted templates, we can synthesize repairs for over 70\% of
the test set in under 20 sec, compared to 58\% repair rate of a \naive
implementation that doesn't use fix templates.

Finally, we conducted an online user-study among 29 participants which showed
that in statistically-significant manner, \toolname's repairs are of much better
quality than the ones from the state-of-the-art tool \seminal. This improvement
shown by our data-driven method is especially significant because \seminal
incorporates several expert-guided heuristics for improving the quality of error
messages by biasing its reports towards simpler and more useful ones. Thus, our
results demonstrate the unreasonable effectiveness of data for generating better
error messages.
