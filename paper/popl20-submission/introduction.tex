\section{Introduction}
\label{sec:intro}

%%% Motivation and the problem
The increasing number of computer science related
jobs~\citep[][]{compsci-demand} in the recent years has resulted in an
unprecedented demand for computer science education. Colleges and universities
have more students than ever~\citep[][]{compsci-classes} enrolled to their
computer science classes and their numbers will only increase in the foreseeable
future. Other students wanting to join this growth of technology and computing,
have turned to Massive Open Online Courses (MOOCs)~\citep[][]{moocs} to get the
appropriate knowledge in order to pursue their dream in the technology job
market. While computer science education has become much more accessible with
these larger classrooms over the years, one may ask if its \emph{quality} has
remained the same as of the more traditional smaller classrooms, and
specifically the feedback that students get for homework and exams.

%%% Good properties of a solution
Recent research has focused on providing \emph{fully automated feedback} to
students for the programming assignments that these classes usually include. In
this paper we propose such a solution, that can be used to give personalized
feedback to students for introductory programming exercises without requiring
any instructor effort. Previous work has exploited the advances in \emph{program
repair} research to generate such feedback.
% TODO: Cite clara, autoproof, sarfgen, ... here

By repairing an incorrect student attempt on a programming assignment and
producing a \emph{minimal} repair \wrt some edit-distance metric, so it can be
as close as possible to the original one, we can generate \emph{high-quality}
feedback for that attempt. Furthermore, the repair algorithm we propose must be
able to \emph{generalize} over different programming assignments and to not be
specific to existing ones only. In this paper we focus on generating such
repairs that will enable better feedback generation and leave the latter part as
future work.

%%% Current state of the art
% Failing test cases
Presenting students with \emph{failing test cases} still remains one of the most
common approaches for providing feedback on erroneous programming assignments
attempts. These test cases can be carefully selected by the instructor to guide
their students in debugging their code. However, for students that are not yet
so experienced in programming, such feedback may not be sufficient. More
targeted feedback is needed in this case, that will highlight possible program
locations that are responsible for the program errors, and may give possible
suggestions that will lead the student to a correct solution.

% Fault localization FIXME: make this better
Recent research~\citep[][]{Seidel:2017, Zhang2014-lv} has proposed the use of
\emph{fault localization} for more guided feedback. Fault localization is the
task of identifying possible program elements (\eg lines, expressions \etc) that
are the cause of the program error at hand. While these techniques can pinpoint
with high accuracy the precise location in the student's code that cause the
error and needs to be fixed, inexperienced programmers can still be confused by
such feedback. However, fault localization combined with \emph{program repair}
can provide the appropriate feedback for those novice programmers.

% Program repair
Recent automated systems for providing feedback via \emph{program repair}, like
AutoGrader [TODO: cite] demand a lot of manual effort from the instructor and
their understanding of the system details. AutoGrader requires a reference
solution per programming assignment and a custom error model that will help
repair incorrect student attempts, thus the instructor has to spent extra time
for each assignment, while the algorithm finding the repairs is still very
expensive due to constraint-solving. Systems like CLARA [TODO: cite] require
much less manual effort from the instructor by using clustering and machine
learning techniques on previous student attempts on the programming assignments.
While the repairs are generated relatively quickly, their program matching
between previous correct attempts and the new incorrect ones, can often lead to
imprecise and not minimal repairs. Moreover, their use of Integer Linear
Programming (ILP) for variable alignment between possible local repairs can hurt
its scalability. [TODO: Section N] provides a detailed survey of related work.
% TODO: Add Seminal(it's the one on our human study) here?
% TODO: Maybe add another tool?

% FIXME: help here!!
%%% Our technique
\mypara{Data-Driven Program Repair}
In this paper, we introduce \toolname, a \emph{data-driven} approach to
repairing novice attempts on programming assignments based on supervised
learning. \toolname uses a large dataset with pairs of ill-typed programs and
their subsequent fixes, to \emph{automatically learn models} that localize
errors, suggest template fixes, and uses \emph{program synthesis} to turn those
templates into \emph{program repairs}. Given a new ill-typed program, \toolname
generates a list of potential solutions ranked by likelihood and a
\emph{edit-distance} metric. We evaluate \toolname by comparing its accuracy on
a set of over 4,500 ill-typed \ocaml programs drawn from two instances of an
introductory programming course.


% 1. ``We identify an important problem in the world.'' Be more specific than
% just ``bugs''. Are we focusing on novices and students or are we focusing
% on general software defects? Are we focusing on strongly-typed functional
% languages or are we proposing something generic? What ``news article'' or
% ``survey paper'' citations can you list here to convince me that this is a
% big deal?

% 2. ``Here are the properties that a good solution must have.'' Pick three.
% Here are some examples: must be applicable to students; must produce
% answers quickly; must produce answers that are very close to what humans
% would do; must apply to programs from a wide range of application domains.

% 3. ``Here is the current state of the art. Note that each of these fails to
% obtain at least one of the properties above.'' Candidates: manual debugging
% (bad because of X and Y); using something like genprog (bad because of X
% and Z); using pure fault localization (bad because of A and B); using delta
% debugging or git/svn blame (bad because of P and Q); using something like
% Nate or Sherrloc (bad because of Q and R).

% 4. ``Here are our two or three insights. These insights are the
% underpinning of our solution.'' What are the most important ones?
% Candidates: blame-labeled training sets are available; student repairs fall
% into a reasonable number of categories (admitting a classification
% technique); program repair can be viewed as a synthesis problem;
% generalized ASTs can handle typed and untyped program manipulations.

% 5. ``We combine those insights into TECHNIQUE. It works by steps A, B and
% C, which allow it to obtain the properties P1, P2, and P3 of a good
% solution.'' Briefly condense the steps from Section 2 here.

% 6. ``We evaluate our technique. For Property P1, we use metric M1 and must
% be at least as good as S1 to be successful. For Property P2, we use metric
% M2 and must be at least as good as S2 to be successful. We obtain property
% P3 by construction.'' Fill in the blanks. In addition, for every benchmark
% set or human study used, indicate why you are sampling correctly --- why
% those results are likely to generalize.

% The contributions of this paper are as follows:
% \begin{itemize}
%   \item The algorithm. FIXME.
%   \item The dataset. FIXME --- is this a contribution?
%   \item The empirical evaluation. FIXME.
%   \item The human study. FIXME.
% \end{itemize}

